{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c7e64e22",
   "metadata": {},
   "source": [
    "# Exploração Inicial — Dataset Orders (Olist)\n",
    "\n",
    "Este notebook faz parte do projeto **olist-orders-analysis**, cujo objetivo é analisar\n",
    "o comportamento dos pedidos da base pública da Olist, aplicando conceitos fundamentais\n",
    "de análise de dados com **Python, Pandas e Numpy**.\n",
    "\n",
    "Neste primeiro notebook, o foco está exclusivamente no dataset **orders**, realizando:\n",
    "- entendimento da estrutura dos dados\n",
    "- análise exploratória inicial\n",
    "- identificação de padrões, assimetrias e possíveis problemas de qualidade\n",
    "- geração de hipóteses que serão exploradas nos próximos notebooks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12e586a8",
   "metadata": {},
   "source": [
    "## Objetivo deste notebook\n",
    "\n",
    "O objetivo deste notebook é realizar uma **análise exploratória inicial (EDA)** do dataset\n",
    "`orders.csv`, respondendo perguntas como:\n",
    "\n",
    "- Quantos pedidos existem no dataset?\n",
    "- Qual o status mais comum dos pedidos?\n",
    "- Como os pedidos se distribuem ao longo do tempo?\n",
    "- Existem indícios de assimetria ou caudas longas nos dados?\n",
    "- Há dados ausentes ou inconsistências relevantes?\n",
    "\n",
    "As respostas a essas perguntas servirão de base para a definição das métricas\n",
    "que serão construídas nos próximos notebooks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eba38043",
   "metadata": {},
   "source": [
    "## Dataset utilizado\n",
    "\n",
    "Neste notebook utilizamos o arquivo:\n",
    "\n",
    "- `data/raw/olist_orders_dataset.csv`\n",
    "\n",
    "Este dataset contém informações a nível de pedido, incluindo:\n",
    "- identificador do pedido\n",
    "- identificador do cliente\n",
    "- status do pedido\n",
    "- datas relacionadas ao ciclo do pedido (compra, aprovação, envio, entrega)\n",
    "\n",
    "Neste estágio, os dados são utilizados **sem qualquer tratamento prévio**,\n",
    "respeitando a camada *raw* do pipeline analítico.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f782d282",
   "metadata": {},
   "source": [
    "## Abordagem de análise\n",
    "\n",
    "A exploração dos dados seguirá os seguintes passos:\n",
    "\n",
    "1. Leitura do dataset e inspeção inicial da estrutura\n",
    "2. Análise dos tipos de dados e valores ausentes\n",
    "3. Exploração das variáveis categóricas (ex: status do pedido)\n",
    "4. Análise temporal básica dos pedidos\n",
    "5. Observação de estatísticas descritivas relevantes\n",
    "6. Registro de insights e hipóteses iniciais\n",
    "\n",
    "Nenhuma transformação definitiva será aplicada neste notebook.\n",
    "O objetivo é **entender os dados antes de modelá-los**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "792b302f",
   "metadata": {},
   "source": [
    "## Observações importantes\n",
    "\n",
    "- Este notebook não tem como objetivo gerar métricas finais\n",
    "- Nenhuma decisão de negócio será tomada aqui\n",
    "- Possíveis problemas ou inconsistências serão apenas identificados, não corrigidos\n",
    "\n",
    "Correções, tratamentos e métricas serão implementados\n",
    "nos notebooks seguintes, respeitando o pipeline analítico do projeto.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ed3fbbd",
   "metadata": {},
   "source": [
    "## Checklist da exploração\n",
    "\n",
    "Ao final deste notebook, esperamos ter clareza sobre:\n",
    "\n",
    "- [ ] Estrutura geral do dataset\n",
    "- [ ] Volume total de pedidos\n",
    "- [ ] Distribuição dos status\n",
    "- [ ] Cobertura temporal dos dados\n",
    "- [ ] Presença de dados ausentes\n",
    "- [ ] Validação e conversão de colunas temporais\n",
    "- [ ] Possíveis assimetrias ou padrões relevantes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fe50c17b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eae098c",
   "metadata": {},
   "source": [
    "## Carregamento do dataset\n",
    "\n",
    "Antes de qualquer análise, é necessário carregar o dataset principal que será utilizado ao longo deste notebook.\n",
    "\n",
    "O arquivo `orders.csv` contém informações centrais sobre os pedidos realizados na plataforma da Olist, incluindo identificadores, status do pedido e timestamps relevantes do ciclo de compra.\n",
    "\n",
    "Neste bloco, realizaremos:\n",
    "- A leitura do arquivo CSV a partir da camada de dados brutos (`data/raw`)\n",
    "- A criação do DataFrame inicial que servirá como base para a exploração exploratória\n",
    "\n",
    "O objetivo aqui **não é transformar, limpar ou validar os dados**, mas apenas **garantir que o dataset seja carregado corretamente** para as etapas seguintes de inspeção e entendimento da sua estrutura."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "49a85f06",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = \"../data/raw/olist_orders_dataset.csv\"\n",
    "orders_df = pd.read_csv(DATA_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8590bbf",
   "metadata": {},
   "source": [
    "## Inspeção inicial dos dados\n",
    "\n",
    "Após o carregamento do dataset, o próximo passo é realizar uma inspeção inicial para compreender sua estrutura básica.\n",
    "\n",
    "Nesta etapa, buscamos responder perguntas simples, porém fundamentais, como:\n",
    "- Quantas linhas e colunas o dataset possui\n",
    "- Quais informações cada linha representa\n",
    "- Quais tipos de dados estão presentes\n",
    "- Se existem valores ausentes nas colunas\n",
    "\n",
    "Essas verificações ajudam a confirmar se o dataset está consistente com a documentação esperada e orientam decisões futuras, como conversões de tipo e análises mais específicas.\n",
    "\n",
    "Neste bloco, realizaremos:\n",
    "- A visualização das primeiras observações do dataset\n",
    "- A inspeção dos tipos de dados e da presença de valores nulos\n",
    "\n",
    "O objetivo aqui **não é analisar padrões ou métricas**, mas sim **entender a estrutura dos dados** antes de avançar para etapas mais profundas da exploração."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d0223aae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>order_id</th>\n",
       "      <th>customer_id</th>\n",
       "      <th>order_status</th>\n",
       "      <th>order_purchase_timestamp</th>\n",
       "      <th>order_approved_at</th>\n",
       "      <th>order_delivered_carrier_date</th>\n",
       "      <th>order_delivered_customer_date</th>\n",
       "      <th>order_estimated_delivery_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>e481f51cbdc54678b7cc49136f2d6af7</td>\n",
       "      <td>9ef432eb6251297304e76186b10a928d</td>\n",
       "      <td>delivered</td>\n",
       "      <td>2017-10-02 10:56:33</td>\n",
       "      <td>2017-10-02 11:07:15</td>\n",
       "      <td>2017-10-04 19:55:00</td>\n",
       "      <td>2017-10-10 21:25:13</td>\n",
       "      <td>2017-10-18 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>53cdb2fc8bc7dce0b6741e2150273451</td>\n",
       "      <td>b0830fb4747a6c6d20dea0b8c802d7ef</td>\n",
       "      <td>delivered</td>\n",
       "      <td>2018-07-24 20:41:37</td>\n",
       "      <td>2018-07-26 03:24:27</td>\n",
       "      <td>2018-07-26 14:31:00</td>\n",
       "      <td>2018-08-07 15:27:45</td>\n",
       "      <td>2018-08-13 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>47770eb9100c2d0c44946d9cf07ec65d</td>\n",
       "      <td>41ce2a54c0b03bf3443c3d931a367089</td>\n",
       "      <td>delivered</td>\n",
       "      <td>2018-08-08 08:38:49</td>\n",
       "      <td>2018-08-08 08:55:23</td>\n",
       "      <td>2018-08-08 13:50:00</td>\n",
       "      <td>2018-08-17 18:06:29</td>\n",
       "      <td>2018-09-04 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>949d5b44dbf5de918fe9c16f97b45f8a</td>\n",
       "      <td>f88197465ea7920adcdbec7375364d82</td>\n",
       "      <td>delivered</td>\n",
       "      <td>2017-11-18 19:28:06</td>\n",
       "      <td>2017-11-18 19:45:59</td>\n",
       "      <td>2017-11-22 13:39:59</td>\n",
       "      <td>2017-12-02 00:28:42</td>\n",
       "      <td>2017-12-15 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ad21c59c0840e6cb83a9ceb5573f8159</td>\n",
       "      <td>8ab97904e6daea8866dbdbc4fb7aad2c</td>\n",
       "      <td>delivered</td>\n",
       "      <td>2018-02-13 21:18:39</td>\n",
       "      <td>2018-02-13 22:20:29</td>\n",
       "      <td>2018-02-14 19:46:34</td>\n",
       "      <td>2018-02-16 18:17:02</td>\n",
       "      <td>2018-02-26 00:00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           order_id                       customer_id  \\\n",
       "0  e481f51cbdc54678b7cc49136f2d6af7  9ef432eb6251297304e76186b10a928d   \n",
       "1  53cdb2fc8bc7dce0b6741e2150273451  b0830fb4747a6c6d20dea0b8c802d7ef   \n",
       "2  47770eb9100c2d0c44946d9cf07ec65d  41ce2a54c0b03bf3443c3d931a367089   \n",
       "3  949d5b44dbf5de918fe9c16f97b45f8a  f88197465ea7920adcdbec7375364d82   \n",
       "4  ad21c59c0840e6cb83a9ceb5573f8159  8ab97904e6daea8866dbdbc4fb7aad2c   \n",
       "\n",
       "  order_status order_purchase_timestamp    order_approved_at  \\\n",
       "0    delivered      2017-10-02 10:56:33  2017-10-02 11:07:15   \n",
       "1    delivered      2018-07-24 20:41:37  2018-07-26 03:24:27   \n",
       "2    delivered      2018-08-08 08:38:49  2018-08-08 08:55:23   \n",
       "3    delivered      2017-11-18 19:28:06  2017-11-18 19:45:59   \n",
       "4    delivered      2018-02-13 21:18:39  2018-02-13 22:20:29   \n",
       "\n",
       "  order_delivered_carrier_date order_delivered_customer_date  \\\n",
       "0          2017-10-04 19:55:00           2017-10-10 21:25:13   \n",
       "1          2018-07-26 14:31:00           2018-08-07 15:27:45   \n",
       "2          2018-08-08 13:50:00           2018-08-17 18:06:29   \n",
       "3          2017-11-22 13:39:59           2017-12-02 00:28:42   \n",
       "4          2018-02-14 19:46:34           2018-02-16 18:17:02   \n",
       "\n",
       "  order_estimated_delivery_date  \n",
       "0           2017-10-18 00:00:00  \n",
       "1           2018-08-13 00:00:00  \n",
       "2           2018-09-04 00:00:00  \n",
       "3           2017-12-15 00:00:00  \n",
       "4           2018-02-26 00:00:00  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "orders_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9fe3c0e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 99441 entries, 0 to 99440\n",
      "Data columns (total 8 columns):\n",
      " #   Column                         Non-Null Count  Dtype \n",
      "---  ------                         --------------  ----- \n",
      " 0   order_id                       99441 non-null  object\n",
      " 1   customer_id                    99441 non-null  object\n",
      " 2   order_status                   99441 non-null  object\n",
      " 3   order_purchase_timestamp       99441 non-null  object\n",
      " 4   order_approved_at              99281 non-null  object\n",
      " 5   order_delivered_carrier_date   97658 non-null  object\n",
      " 6   order_delivered_customer_date  96476 non-null  object\n",
      " 7   order_estimated_delivery_date  99441 non-null  object\n",
      "dtypes: object(8)\n",
      "memory usage: 6.1+ MB\n"
     ]
    }
   ],
   "source": [
    "orders_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d46ee82",
   "metadata": {},
   "source": [
    "## Estrutura geral do dataset\n",
    "\n",
    "Antes de avançarmos para análises mais específicas, é importante compreender a dimensão do dataset com o qual estamos trabalhando.\n",
    "\n",
    "Nesta etapa, analisamos:\n",
    "- O número total de registros (linhas)\n",
    "- O número de variáveis disponíveis (colunas)\n",
    "\n",
    "Essa informação é fundamental para contextualizar as análises seguintes, pois o volume de dados influencia interpretações estatísticas, desempenho computacional e até mesmo a representatividade dos resultados.\n",
    "\n",
    "O objetivo aqui é **obter uma visão quantitativa básica do dataset**, sem qualquer transformação ou filtragem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "201aaa20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(99441, 8)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "orders_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7e4f4de",
   "metadata": {},
   "source": [
    "## Volume total de pedidos\n",
    "\n",
    "Antes de explorar distribuições, padrões ou métricas derivadas, é fundamental compreender o volume total de pedidos presente no dataset.\n",
    "\n",
    "Nesta etapa, avaliamos:\n",
    "- A quantidade total de pedidos registrados\n",
    "- A escala dos dados com os quais a análise será realizada\n",
    "\n",
    "Essa informação ajuda a contextualizar análises futuras, como distribuições de status, cobertura temporal e possíveis segmentações, além de fornecer uma noção inicial sobre a representatividade do conjunto de dados.\n",
    "\n",
    "O objetivo aqui é **quantificar o volume bruto de pedidos**, sem qualquer tipo de filtragem ou agregação."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "55049c9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "99441"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(orders_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7213151f",
   "metadata": {},
   "source": [
    "## Distribuição dos status dos pedidos\n",
    "\n",
    "Para compreender o comportamento geral dos pedidos ao longo do seu ciclo de vida, é importante analisar a distribuição dos diferentes status presentes no dataset.\n",
    "\n",
    "Nesta etapa, investigamos:\n",
    "- A frequência absoluta de cada status de pedido\n",
    "- A proporção relativa (percentual) de cada status em relação ao total de pedidos\n",
    "\n",
    "Essa análise fornece uma visão inicial sobre:\n",
    "- O estágio predominante dos pedidos (entregues, cancelados, em processamento, etc.)\n",
    "- Possíveis desequilíbrios entre estados do ciclo de vida\n",
    "- Indícios iniciais de gargalos operacionais ou padrões relevantes\n",
    "\n",
    "O objetivo aqui é **entender como os pedidos estão distribuídos entre seus status**, sem ainda buscar explicações causais ou métricas mais avançadas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5867bbdb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "order_status\n",
       "delivered      96478\n",
       "shipped         1107\n",
       "canceled         625\n",
       "unavailable      609\n",
       "invoiced         314\n",
       "processing       301\n",
       "created            5\n",
       "approved           2\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "orders_df['order_status'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "368ee6c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "order_status\n",
       "delivered      0.970203\n",
       "shipped        0.011132\n",
       "canceled       0.006285\n",
       "unavailable    0.006124\n",
       "invoiced       0.003158\n",
       "processing     0.003027\n",
       "created        0.000050\n",
       "approved       0.000020\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "orders_df['order_status'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65878568",
   "metadata": {},
   "source": [
    "## Conversão consciente de colunas temporais e validações leves\n",
    "\n",
    "Antes de avançarmos para análises de padrões ou possíveis assimetrias, é fundamental garantir que as colunas temporais do dataset estejam corretamente tipadas como datas.\n",
    "\n",
    "Trabalhar com colunas temporais como `string` pode gerar interpretações incorretas, especialmente em análises de cobertura temporal, ordenação cronológica e cálculos de intervalo de tempo.\n",
    "\n",
    "Neste bloco, realizaremos:\n",
    "- A conversão explícita das colunas temporais para o tipo `datetime`\n",
    "- Validações leves para compreender a presença de valores ausentes\n",
    "- Verificações simples de consistência temporal\n",
    "\n",
    "O objetivo aqui **não é limpar ou corrigir dados**, mas sim **entender sua estrutura e possíveis limitações**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d9b4108b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lista de colunas temporais do dataset orders\n",
    "date_columns = [\n",
    "    'order_purchase_timestamp',\n",
    "    'order_approved_at',\n",
    "    'order_delivered_carrier_date',\n",
    "    'order_delivered_customer_date',\n",
    "    'order_estimated_delivery_date'\n",
    "]\n",
    "\n",
    "# Conversão explícita para datetime\n",
    "for col in date_columns:\n",
    "    orders_df[col] = pd.to_datetime(orders_df[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3dd85c26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "order_purchase_timestamp            0\n",
       "order_approved_at                 160\n",
       "order_delivered_carrier_date     1783\n",
       "order_delivered_customer_date    2965\n",
       "order_estimated_delivery_date       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verificando valores ausentes nas colunas temporais\n",
    "orders_df[date_columns].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b8863eff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(0)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Quantidade de pedidos entregues antes da data de compra (inconsistência lógica)\n",
    "(orders_df['order_delivered_customer_date'] < orders_df['order_purchase_timestamp']).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "17f6bc26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>order_purchase_timestamp</th>\n",
       "      <th>order_approved_at</th>\n",
       "      <th>order_delivered_carrier_date</th>\n",
       "      <th>order_delivered_customer_date</th>\n",
       "      <th>order_estimated_delivery_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>99441</td>\n",
       "      <td>99281</td>\n",
       "      <td>97658</td>\n",
       "      <td>96476</td>\n",
       "      <td>99441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2017-12-31 08:43:12.776581120</td>\n",
       "      <td>2017-12-31 18:35:24.098800128</td>\n",
       "      <td>2018-01-04 21:49:48.138278656</td>\n",
       "      <td>2018-01-14 12:09:19.035542272</td>\n",
       "      <td>2018-01-24 03:08:37.730111232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2016-09-04 21:15:19</td>\n",
       "      <td>2016-09-15 12:16:38</td>\n",
       "      <td>2016-10-08 10:34:01</td>\n",
       "      <td>2016-10-11 13:46:32</td>\n",
       "      <td>2016-09-30 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2017-09-12 14:46:19</td>\n",
       "      <td>2017-09-12 23:24:16</td>\n",
       "      <td>2017-09-15 22:28:50.249999872</td>\n",
       "      <td>2017-09-25 22:07:22.249999872</td>\n",
       "      <td>2017-10-03 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2018-01-18 23:04:36</td>\n",
       "      <td>2018-01-19 11:36:13</td>\n",
       "      <td>2018-01-24 16:10:58</td>\n",
       "      <td>2018-02-02 19:28:10.500000</td>\n",
       "      <td>2018-02-15 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2018-05-04 15:42:16</td>\n",
       "      <td>2018-05-04 20:35:10</td>\n",
       "      <td>2018-05-08 13:37:45</td>\n",
       "      <td>2018-05-15 22:48:52.249999872</td>\n",
       "      <td>2018-05-25 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2018-10-17 17:30:18</td>\n",
       "      <td>2018-09-03 17:40:06</td>\n",
       "      <td>2018-09-11 19:48:28</td>\n",
       "      <td>2018-10-17 13:22:46</td>\n",
       "      <td>2018-11-12 00:00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            order_purchase_timestamp              order_approved_at  \\\n",
       "count                          99441                          99281   \n",
       "mean   2017-12-31 08:43:12.776581120  2017-12-31 18:35:24.098800128   \n",
       "min              2016-09-04 21:15:19            2016-09-15 12:16:38   \n",
       "25%              2017-09-12 14:46:19            2017-09-12 23:24:16   \n",
       "50%              2018-01-18 23:04:36            2018-01-19 11:36:13   \n",
       "75%              2018-05-04 15:42:16            2018-05-04 20:35:10   \n",
       "max              2018-10-17 17:30:18            2018-09-03 17:40:06   \n",
       "\n",
       "        order_delivered_carrier_date  order_delivered_customer_date  \\\n",
       "count                          97658                          96476   \n",
       "mean   2018-01-04 21:49:48.138278656  2018-01-14 12:09:19.035542272   \n",
       "min              2016-10-08 10:34:01            2016-10-11 13:46:32   \n",
       "25%    2017-09-15 22:28:50.249999872  2017-09-25 22:07:22.249999872   \n",
       "50%              2018-01-24 16:10:58     2018-02-02 19:28:10.500000   \n",
       "75%              2018-05-08 13:37:45  2018-05-15 22:48:52.249999872   \n",
       "max              2018-09-11 19:48:28            2018-10-17 13:22:46   \n",
       "\n",
       "       order_estimated_delivery_date  \n",
       "count                          99441  \n",
       "mean   2018-01-24 03:08:37.730111232  \n",
       "min              2016-09-30 00:00:00  \n",
       "25%              2017-10-03 00:00:00  \n",
       "50%              2018-02-15 00:00:00  \n",
       "75%              2018-05-25 00:00:00  \n",
       "max              2018-11-12 00:00:00  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Estatísticas descritivas das colunas temporais\n",
    "orders_df[date_columns].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45f148bc",
   "metadata": {},
   "source": [
    "## Cobertura temporal dos dados\n",
    "\n",
    "Antes de analisar padrões, tendências ou possíveis assimetrias, é essencial compreender o período temporal coberto pelo dataset.\n",
    "\n",
    "Nesta etapa, avaliamos:\n",
    "- A data mais antiga de compra registrada\n",
    "- A data mais recente de compra registrada\n",
    "\n",
    "Essa verificação permite entender:\n",
    "- A extensão temporal dos dados disponíveis\n",
    "- Se o dataset representa um período contínuo ou fragmentado\n",
    "- Possíveis limitações para análises temporais futuras\n",
    "\n",
    "O objetivo aqui é **delimitar o intervalo temporal dos pedidos**, sem ainda investigar sazonalidade, tendências ou variações ao longo do tempo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1df351c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Timestamp('2016-09-04 21:15:19'), Timestamp('2018-10-17 17:30:18'))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "orders_df['order_purchase_timestamp'].min(), orders_df['order_purchase_timestamp'].max()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8e59181",
   "metadata": {},
   "source": [
    "## Presença de dados ausentes\n",
    "\n",
    "Antes de avançar para a identificação de padrões ou assimetrias, é fundamental avaliar a presença de valores ausentes no dataset.\n",
    "\n",
    "Nesta etapa, verificamos:\n",
    "- A quantidade de valores nulos em cada coluna\n",
    "- Quais campos apresentam ausência de dados\n",
    "- A magnitude dessas ausências em relação ao volume total de registros\n",
    "\n",
    "Essa análise é importante para:\n",
    "- Compreender limitações estruturais dos dados\n",
    "- Antecipar possíveis impactos em análises futuras\n",
    "- Avaliar a necessidade (ou não) de tratamento de dados ausentes em etapas posteriores\n",
    "\n",
    "O objetivo aqui **não é realizar imputação ou limpeza**, mas apenas **mapear a existência e a distribuição de valores ausentes** no dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "28565e39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "order_id                            0\n",
       "customer_id                         0\n",
       "order_status                        0\n",
       "order_purchase_timestamp            0\n",
       "order_approved_at                 160\n",
       "order_delivered_carrier_date     1783\n",
       "order_delivered_customer_date    2965\n",
       "order_estimated_delivery_date       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "orders_df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13e21f27",
   "metadata": {},
   "source": [
    "## Possíveis assimetrias ou padrões relevantes\n",
    "\n",
    "Após compreender a estrutura do dataset, sua cobertura temporal, a distribuição dos status e a presença de dados ausentes, podemos agora realizar uma exploração inicial em busca de possíveis assimetrias ou padrões relevantes.\n",
    "\n",
    "Nesta etapa, buscamos:\n",
    "- Identificar distribuições desbalanceadas\n",
    "- Observar concentrações atípicas ao longo do tempo\n",
    "- Detectar indícios iniciais de comportamento não uniforme nos dados\n",
    "\n",
    "É importante destacar que esta análise:\n",
    "- Não tem como objetivo explicar causas\n",
    "- Não utiliza métricas avançadas\n",
    "- Não busca conclusões definitivas\n",
    "\n",
    "O foco aqui é **levantar hipóteses iniciais** e **mapear comportamentos que merecem investigação futura** nos próximos notebooks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "896c771b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "order_purchase_timestamp\n",
       "2016-09-30       4\n",
       "2016-10-31     324\n",
       "2016-11-30       0\n",
       "2016-12-31       1\n",
       "2017-01-31     800\n",
       "2017-02-28    1780\n",
       "2017-03-31    2682\n",
       "2017-04-30    2404\n",
       "2017-05-31    3700\n",
       "2017-06-30    3245\n",
       "2017-07-31    4026\n",
       "2017-08-31    4331\n",
       "2017-09-30    4285\n",
       "2017-10-31    4631\n",
       "2017-11-30    7544\n",
       "2017-12-31    5673\n",
       "2018-01-31    7269\n",
       "2018-02-28    6728\n",
       "2018-03-31    7211\n",
       "2018-04-30    6939\n",
       "2018-05-31    6873\n",
       "2018-06-30    6167\n",
       "2018-07-31    6292\n",
       "2018-08-31    6512\n",
       "2018-09-30      16\n",
       "2018-10-31       4\n",
       "Freq: ME, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(\n",
    "    orders_df\n",
    "    .set_index('order_purchase_timestamp')\n",
    "    .resample('ME')\n",
    "    .size()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ef9b198",
   "metadata": {},
   "source": [
    "Observações iniciais:\n",
    "- A distribuição de pedidos ao longo do tempo não é uniforme\n",
    "- Há períodos com maior concentração de pedidos\n",
    "- Esses padrões serão explorados com mais profundidade em análises futuras"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "olist-analysis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
